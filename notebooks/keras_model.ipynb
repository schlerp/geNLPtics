{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.utils.all_utils\n",
    "import keras.callbacks\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17959\n"
     ]
    }
   ],
   "source": [
    "def parse_fasta_dataset(file_path: str = \"../data/LTP_09_2021_compressed.fasta\", max_seqs:int = False) -> List[Dict[str, str]]:\n",
    "    dataset = []\n",
    "    current_idx = 0\n",
    "    current_meta = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \">\":\n",
    "                if current_meta != {}:\n",
    "                    current_meta[\"sequence\"] = current_meta[\"sequence\"].strip()\n",
    "                    dataset.append(current_meta)\n",
    "                line_list = line.replace(\"\\n\", \"\").replace(\">\", \"\").split(\"\\t\")\n",
    "                if len(line_list) < 2:\n",
    "                    current_meta  = {key: line_list[idx] for idx, key in enumerate([\"name\"])}\n",
    "                elif len(line_list) < 3:\n",
    "                    current_meta  = {key: line_list[idx] for idx, key in enumerate([\"id\", \"name\"])}\n",
    "                else:\n",
    "                    current_meta  = {key: line_list[idx] for idx, key in enumerate([\"id\", \"name\", \"tags\"])}\n",
    "                    current_meta[\"tags\"] = current_meta[\"tags\"].split(\";\")\n",
    "                current_meta[\"sequence\"] = \"\"\n",
    "                current_idx += 1\n",
    "                if current_idx > max_seqs and max_seqs>=1:\n",
    "                    break\n",
    "            else:\n",
    "                current_meta[\"sequence\"] += line.replace(\"\\n\", \" \")\n",
    "    return dataset\n",
    "\n",
    "dataset = parse_fasta_dataset(max_seqs=-1)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'AB681979',\n",
       " 'name': 'Trabulsiella guamensis',\n",
       " 'tags': ['Bacteria',\n",
       "  'Proteobacteria',\n",
       "  'Gammaproteobacteria',\n",
       "  'Enterobacterales',\n",
       "  'Enterobacteriaceae',\n",
       "  'Trabulsiella'],\n",
       " 'sequence': 'AUUGAACGCU GGCGGCAGGC CUAACACAUG CAAGUCGAGC GGCAGCGGGG GAAAGCUUGC UUUCCCGCCG GCGAGCGGCG GACGGGUGAG UAAUGUCUGG GAAACUGCCU GAUGGAGGGG GAUAACUACU GGAAACGGUA GCUAAUACCG CAUAACGUCU UCGGACCAAA GUGGGGGACC UUCGGGCCUC AUGCCAUCAG AUGUGCCCAG AUGGGAUUAG CUAGUAGGUG GGGUAACGGC UCACCUAGGC GACGAUCCCU AGCUGGUCUG AGAGGAUGAC CAGCCACACU GGAACUGAGA CACGGUCCAG ACUCCUACGG GAGGCAGCAG UGGGGAAUAU UGCACAAUGG GCGCAAGCCU GAUGCAGCCA UGCCGCGUGU AUGAAGAAGG CCUUCGGGUU GUAAAGUACU UUCAGCGGGG AGGAAGGUGU UGUGGUUAAU AACCAGAGCA AUUGACGUUA CCCGCAGAAG AAGCACCGGC UAACUCCGUG CCAGCAGCCG CGGUAAUACG GAGGGUGCAA GCGUUAAUCG GAAUUACUGG GCGUAAAGCG CACGCAGGCG GUCUGUCAAG UCGGAUGUGA AAUCCCCGGG CUCAACCUGG GAACUGCAUC CGAAACUGGC AGGCUUGAGU CUUGUAGAGG GGGGUAGAAU UCCAGGUGUA GCGGUGAAAU GCGUAGAGAU CUGGAGGAAU ACCGGUGGCG AAGGCGGCCC CCUGGACAAA GACUGACGCU CAGGUGCGAA AGCGUGGGGA GCAAACAGGA UUAGAUACCC UGGUAGUCCA CGCCGUAAAC GAUGUCGACU UGGAGGUUGU GCCCUUGAGG CGUGGCUUCC GGAGCUAACG CGUUAAGUCG ACCGCCUGGG GAGUACGGCC GCAAGGUUAA AACUCAAAUG AAUUGACGGG GGCCCGCACA AGCGGUGGAG CAUGUGGUUU AAUUCGAUGC AACGCGAAGA ACCUUACCUG GUCUUGACAU CCACAGAACC CUGUAGAGAU ACGGGGGUGC CUUCGGGAAC UGUGAGACAG GUGCUGCAUG GCUGUCGUCA GCUCGUGUUG UGAAAUGUUG GGUUAAGUCC CGCAACGAGC GCAACCCUUA UCCUUUGUUG CCAGCGGUCC GGCCGGGAAC UCAAAGGAGA CUGCCAGUGA UAAACUGGAG GAAGGUGGGG AUGACGUCAA GUCAUCAUGG CCCUUACGAC CAGGGCUACA CACGUGCUAC AAUGGCAUAU ACAAAGAGAA GCGACCUCGC GAGAGCAAGC GGACCUCAUA AAGUAUGUCG UAGUCCGGAU UGGAGUCUGC AACUCGACUC CAUGAAGUCG GAAUCGCUAG UAAUCGUGGA UCAGAAUGCC ACGGUGAAUA CGUUCCCGGG CCUUGUACAC ACCGCCCGUC ACACCAUGGG AGUGGGUUGC AAAAGAAGUA GGUAGCUUAA CCUUCGGGAG GGCGCUUACC ACUUUGUGAU UCAUGACUGG GGUGAAG'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = set(\"\".join(x[\"sequence\"].replace(\" \", \"\") for x in dataset))\n",
    "encode_dict = {value: idx+1 for idx, value in enumerate(temp)}\n",
    "X = np.array([np.pad(np.array([encode_dict[z] for z in x[\"sequence\"].replace(\" \", \"\")]), (0, 3000))[:2500] for x in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {value for x in dataset for value in x[\"tags\"][:3]}\n",
    "label_encode_dict = {value: idx+1 for idx, value in enumerate(temp)}\n",
    "Y = keras.utils.all_utils.to_categorical(np.array([[label_encode_dict[z] for z in x[\"tags\"][:3]] for x in dataset]))\n",
    "Y = np.array([np.sum(x, 0) for x in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17959, 158)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape: Tuple[int], output_shape: Tuple[int], embed_size: int, vocab_size: int, lstm_size: int=32):\n",
    "    # model input\n",
    "    model_input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # embedding layer\n",
    "    embedding = keras.layers.Embedding(vocab_size, embed_size)(model_input)\n",
    "    # RNN layer\n",
    "    rnn_layer = keras.layers.GRU(lstm_size)(embedding)\n",
    "\n",
    "    # model output\n",
    "    model_output = keras.layers.Dense(output_shape, activation=\"relu\")(rnn_layer)\n",
    "\n",
    "    return keras.Model(inputs=[model_input], outputs=[model_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=X[0].shape, output_shape=Y[0].shape[0], embed_size=128, vocab_size=len(encode_dict)+1, lstm_size=32)\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "train_hx = model.fit(X[:100], Y[:100], validation_split=0.2, epochs=10, callbacks=[keras.callbacks.TensorBoard()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1be35fa6cd7ba76b6b637ae5ebbc3292c3f6fe8b56e54002bc7d184d0bc4977"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
